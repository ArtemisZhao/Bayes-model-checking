---
title: "Simulation Null data"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Preload code and set parameters

```{r}
source("~/project/reproducibility/code/rep_pval.R")
N = 5000
se = 0.5
```


## Simulate the consistent null data

```{r}
bhat1 = rnorm(N,sd=se) 
bhat2 = rnorm(N,sd=se)
```



## Analyze data

The default two-sided p-values

```{r, echo = FALSE}
pval = sapply(1:N, function(x) replication_pvalue(bhat=c(bhat1[x], bhat2[x]), se=c(se,se)))
summary(pval)
length(which(pval<0.05))
hist(pval)
```


Left-tailed p-values

```{r, echo = FALSE}
pval = sapply(1:N, function(x) replication_pvalue_left(bhat=c(bhat1[x], bhat2[x]), se=c(se,se)))
summary(pval)
length(which(pval<0.05))
hist(pval)
```

right-tailed p-values

```{r, echo = FALSE}
pval = sapply(1:N, function(x) replication_pvalue_right(bhat=c(bhat1[x], bhat2[x]), se=c(se,se)))
summary(pval)
length(which(pval<0.05))
hist(pval)
```


The pubbias p-values

```{r, echo = FALSE}
pval = sapply(1:N, function(x) replication_pvalue_pubbias2(bhat=c(bhat1[x], bhat2[x]), se=c(se,se)))
summary(pval)
length(which(pval<0.05))
hist(pval)
```

Not quite right. The proposed test statistic is problematic. 

Can we test how extreme is the observed $\frac{\hat \beta_r}{\hat \beta_o}$?
